{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST WITH SMOTEENN + PCA\n",
    "RECALL IS GETTING HIGH BUT ACCURACY AND PRECISION NOT\n",
    "I HAVE NOTE RESULT RF+ADASYN+PCA,RF+SMOTE+PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "df = pd.read_csv(\"/home/roopal/diabetes_data_preprocessed_big.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].apply(lambda x: 0 if x == 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 88764, 1: 11357})\n"
     ]
    }
   ],
   "source": [
    "df1 = df[['race','gender','age','admission_type_id','discharge_disposition_id','admission_source_id','time_in_hospital','num_lab_procedures','num_procedures','num_medications','number_outpatient','number_emergency','number_inpatient','diag_1','diag_2','diag_3','number_diagnoses','max_glu_serum','A1Cresult','insulin','change','diabetesMed']]\n",
    "df1 = pd.get_dummies(df1, columns=['race'], drop_first = True)\n",
    "y = df['readmitted']\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "import numpy as np\n",
    "df['number_outpatient'] = np.log1p(df['number_outpatient'])\n",
    "df['number_inpatient'] = np.log1p(df['number_inpatient'])\n",
    "df['number_emergency'] = np.log1p(df['number_emergency'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now dataset shape Counter({1: 69476, 0: 37396})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt = SMOTEENN(random_state=20,sampling_strategy='all',ratio=None)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df1,y, test_size=0.20, random_state=0)\n",
    "x_train, y_train = smt.fit_sample(X_train, Y_train)\n",
    "print('Now dataset shape {}'.format(Counter(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#X = x_train.values\n",
    "X_std = StandardScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "# Create a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the eigenvalue, eigenvector pair from high to low\n",
    "eig_pairs.sort(key = lambda x: x[0], reverse= True)\n",
    "\n",
    "# Calculation of Explained Variance from the eigenvalues\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ n for n,i in enumerate(cum_var_exp) if i>90 ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=19)\n",
    "pca.fit(X_std)\n",
    "X_228d = pca.transform(X_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_test.values\n",
    "y_std = StandardScaler().fit_transform(y)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "y_228d = pca.transform(y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.00      0.01     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.77      0.50      0.40    106872\n",
      "weighted avg       0.73      0.65      0.52    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.04      0.08     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.75      0.52      0.44    106872\n",
      "weighted avg       0.72      0.66      0.54    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.09      0.17     37396\n",
      "           1       0.67      0.99      0.80     69476\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    106872\n",
      "   macro avg       0.75      0.54      0.48    106872\n",
      "weighted avg       0.73      0.68      0.58    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.25     37396\n",
      "           1       0.68      0.98      0.80     69476\n",
      "\n",
      "   micro avg       0.69      0.69      0.69    106872\n",
      "   macro avg       0.74      0.56      0.53    106872\n",
      "weighted avg       0.72      0.69      0.61    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.25      0.38     37396\n",
      "           1       0.71      0.97      0.82     69476\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    106872\n",
      "   macro avg       0.77      0.61      0.60    106872\n",
      "weighted avg       0.75      0.72      0.66    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.34      0.49     37396\n",
      "           1       0.73      0.97      0.84     69476\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    106872\n",
      "   macro avg       0.81      0.66      0.66    106872\n",
      "weighted avg       0.78      0.75      0.72    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.45      0.61     37396\n",
      "           1       0.77      0.99      0.86     69476\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    106872\n",
      "   macro avg       0.86      0.72      0.74    106872\n",
      "weighted avg       0.83      0.80      0.77    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81     37396\n",
      "           1       0.85      1.00      0.92     69476\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    106872\n",
      "   macro avg       0.92      0.84      0.86    106872\n",
      "weighted avg       0.90      0.89      0.88    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     37396\n",
      "           1       0.92      1.00      0.96     69476\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    106872\n",
      "   macro avg       0.96      0.91      0.93    106872\n",
      "weighted avg       0.95      0.94      0.94    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     37396\n",
      "           1       0.95      1.00      0.98     69476\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    106872\n",
      "   macro avg       0.98      0.95      0.96    106872\n",
      "weighted avg       0.97      0.97      0.97    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     37396\n",
      "           1       0.98      1.00      0.99     69476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    106872\n",
      "   macro avg       0.99      0.98      0.99    106872\n",
      "weighted avg       0.99      0.99      0.99    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     37396\n",
      "           1       0.99      1.00      1.00     69476\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    106872\n",
      "   macro avg       1.00      0.99      0.99    106872\n",
      "weighted avg       1.00      1.00      1.00    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.00      0.00     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.81      0.50      0.40    106872\n",
      "weighted avg       0.76      0.65      0.51    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.03      0.06     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.76      0.51      0.42    106872\n",
      "weighted avg       0.73      0.66      0.53    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.10      0.17     37396\n",
      "           1       0.67      0.99      0.80     69476\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    106872\n",
      "   macro avg       0.75      0.54      0.49    106872\n",
      "weighted avg       0.73      0.68      0.58    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.26     37396\n",
      "           1       0.68      0.98      0.80     69476\n",
      "\n",
      "   micro avg       0.69      0.69      0.69    106872\n",
      "   macro avg       0.74      0.57      0.53    106872\n",
      "weighted avg       0.72      0.69      0.61    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.24      0.37     37396\n",
      "           1       0.70      0.97      0.82     69476\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    106872\n",
      "   macro avg       0.77      0.61      0.60    106872\n",
      "weighted avg       0.75      0.72      0.66    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49     37396\n",
      "           1       0.73      0.98      0.84     69476\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    106872\n",
      "   macro avg       0.81      0.66      0.66    106872\n",
      "weighted avg       0.79      0.75      0.72    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.45      0.61     37396\n",
      "           1       0.77      0.99      0.86     69476\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    106872\n",
      "   macro avg       0.86      0.72      0.74    106872\n",
      "weighted avg       0.83      0.80      0.78    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82     37396\n",
      "           1       0.86      1.00      0.92     69476\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    106872\n",
      "   macro avg       0.93      0.84      0.87    106872\n",
      "weighted avg       0.91      0.89      0.89    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     37396\n",
      "           1       0.92      1.00      0.96     69476\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    106872\n",
      "   macro avg       0.96      0.92      0.93    106872\n",
      "weighted avg       0.95      0.94      0.94    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     37396\n",
      "           1       0.95      1.00      0.98     69476\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    106872\n",
      "   macro avg       0.98      0.96      0.96    106872\n",
      "weighted avg       0.97      0.97      0.97    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     37396\n",
      "           1       0.98      1.00      0.99     69476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    106872\n",
      "   macro avg       0.99      0.99      0.99    106872\n",
      "weighted avg       0.99      0.99      0.99    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     37396\n",
      "           1       1.00      1.00      1.00     69476\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    106872\n",
      "   macro avg       1.00      1.00      1.00    106872\n",
      "weighted avg       1.00      1.00      1.00    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.00      0.00     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.80      0.50      0.39    106872\n",
      "weighted avg       0.75      0.65      0.51    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.03      0.06     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.76      0.52      0.43    106872\n",
      "weighted avg       0.73      0.66      0.54    106872\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.09      0.17     37396\n",
      "           1       0.67      0.99      0.80     69476\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    106872\n",
      "   macro avg       0.75      0.54      0.48    106872\n",
      "weighted avg       0.73      0.68      0.58    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.14      0.24     37396\n",
      "           1       0.68      0.98      0.80     69476\n",
      "\n",
      "   micro avg       0.69      0.69      0.69    106872\n",
      "   macro avg       0.75      0.56      0.52    106872\n",
      "weighted avg       0.73      0.69      0.61    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.24      0.38     37396\n",
      "           1       0.71      0.97      0.82     69476\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    106872\n",
      "   macro avg       0.77      0.61      0.60    106872\n",
      "weighted avg       0.75      0.72      0.66    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49     37396\n",
      "           1       0.73      0.98      0.84     69476\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    106872\n",
      "   macro avg       0.81      0.66      0.66    106872\n",
      "weighted avg       0.79      0.75      0.72    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.45      0.61     37396\n",
      "           1       0.77      0.99      0.86     69476\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    106872\n",
      "   macro avg       0.86      0.72      0.74    106872\n",
      "weighted avg       0.83      0.80      0.78    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82     37396\n",
      "           1       0.86      1.00      0.92     69476\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    106872\n",
      "   macro avg       0.93      0.84      0.87    106872\n",
      "weighted avg       0.91      0.89      0.88    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     37396\n",
      "           1       0.92      1.00      0.96     69476\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    106872\n",
      "   macro avg       0.96      0.92      0.94    106872\n",
      "weighted avg       0.95      0.94      0.94    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     37396\n",
      "           1       0.95      1.00      0.98     69476\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    106872\n",
      "   macro avg       0.98      0.95      0.96    106872\n",
      "weighted avg       0.97      0.97      0.97    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     37396\n",
      "           1       0.99      1.00      0.99     69476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    106872\n",
      "   macro avg       0.99      0.99      0.99    106872\n",
      "weighted avg       0.99      0.99      0.99    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     37396\n",
      "           1       1.00      1.00      1.00     69476\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    106872\n",
      "   macro avg       1.00      1.00      1.00    106872\n",
      "weighted avg       1.00      1.00      1.00    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.00      0.00     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.81      0.50      0.40    106872\n",
      "weighted avg       0.77      0.65      0.51    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.04      0.07     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.76      0.52      0.43    106872\n",
      "weighted avg       0.73      0.66      0.54    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.10      0.18     37396\n",
      "           1       0.67      0.99      0.80     69476\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    106872\n",
      "   macro avg       0.75      0.54      0.49    106872\n",
      "weighted avg       0.73      0.68      0.58    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.15      0.25     37396\n",
      "           1       0.68      0.98      0.80     69476\n",
      "\n",
      "   micro avg       0.69      0.69      0.69    106872\n",
      "   macro avg       0.75      0.56      0.53    106872\n",
      "weighted avg       0.73      0.69      0.61    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.24      0.37     37396\n",
      "           1       0.70      0.97      0.82     69476\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    106872\n",
      "   macro avg       0.77      0.61      0.60    106872\n",
      "weighted avg       0.75      0.72      0.66    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49     37396\n",
      "           1       0.73      0.98      0.84     69476\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    106872\n",
      "   macro avg       0.81      0.66      0.67    106872\n",
      "weighted avg       0.79      0.75      0.72    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.45      0.61     37396\n",
      "           1       0.77      0.99      0.87     69476\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    106872\n",
      "   macro avg       0.86      0.72      0.74    106872\n",
      "weighted avg       0.83      0.80      0.78    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82     37396\n",
      "           1       0.86      1.00      0.92     69476\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    106872\n",
      "   macro avg       0.93      0.85      0.87    106872\n",
      "weighted avg       0.91      0.89      0.89    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     37396\n",
      "           1       0.92      1.00      0.96     69476\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    106872\n",
      "   macro avg       0.96      0.92      0.94    106872\n",
      "weighted avg       0.95      0.94      0.94    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     37396\n",
      "           1       0.95      1.00      0.98     69476\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    106872\n",
      "   macro avg       0.98      0.96      0.96    106872\n",
      "weighted avg       0.97      0.97      0.97    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     37396\n",
      "           1       0.99      1.00      0.99     69476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    106872\n",
      "   macro avg       0.99      0.99      0.99    106872\n",
      "weighted avg       0.99      0.99      0.99    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     37396\n",
      "           1       1.00      1.00      1.00     69476\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    106872\n",
      "   macro avg       1.00      1.00      1.00    106872\n",
      "weighted avg       1.00      1.00      1.00    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.00      0.00     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.81      0.50      0.40    106872\n",
      "weighted avg       0.76      0.65      0.51    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.04      0.07     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.75      0.52      0.43    106872\n",
      "weighted avg       0.72      0.66      0.54    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.10      0.17     37396\n",
      "           1       0.67      0.99      0.80     69476\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    106872\n",
      "   macro avg       0.75      0.54      0.49    106872\n",
      "weighted avg       0.73      0.68      0.58    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.14      0.25     37396\n",
      "           1       0.68      0.98      0.80     69476\n",
      "\n",
      "   micro avg       0.69      0.69      0.69    106872\n",
      "   macro avg       0.75      0.56      0.52    106872\n",
      "weighted avg       0.73      0.69      0.61    106872\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.24      0.38     37396\n",
      "           1       0.70      0.97      0.82     69476\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    106872\n",
      "   macro avg       0.77      0.61      0.60    106872\n",
      "weighted avg       0.75      0.72      0.66    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49     37396\n",
      "           1       0.73      0.98      0.84     69476\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    106872\n",
      "   macro avg       0.81      0.66      0.66    106872\n",
      "weighted avg       0.79      0.75      0.72    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.45      0.61     37396\n",
      "           1       0.77      0.99      0.87     69476\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    106872\n",
      "   macro avg       0.86      0.72      0.74    106872\n",
      "weighted avg       0.83      0.80      0.78    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82     37396\n",
      "           1       0.86      1.00      0.92     69476\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    106872\n",
      "   macro avg       0.93      0.85      0.87    106872\n",
      "weighted avg       0.91      0.89      0.89    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     37396\n",
      "           1       0.92      1.00      0.96     69476\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    106872\n",
      "   macro avg       0.96      0.92      0.94    106872\n",
      "weighted avg       0.95      0.94      0.94    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     37396\n",
      "           1       0.95      1.00      0.98     69476\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    106872\n",
      "   macro avg       0.98      0.95      0.96    106872\n",
      "weighted avg       0.97      0.97      0.97    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     37396\n",
      "           1       0.99      1.00      0.99     69476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    106872\n",
      "   macro avg       0.99      0.99      0.99    106872\n",
      "weighted avg       0.99      0.99      0.99    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     37396\n",
      "           1       1.00      1.00      1.00     69476\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    106872\n",
      "   macro avg       1.00      1.00      1.00    106872\n",
      "weighted avg       1.00      1.00      1.00    106872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "import pickle\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "auc = []\n",
    "f1 = []\n",
    "f= open(\"tr.txt\",\"a+\")\n",
    "f.write('accuracy'+\",\"+'Precision'+\",\"+'Recall'+\",\"+'AUC')\n",
    "f.write(\"\\n\")\n",
    "for i in [50,100,200,250,300]:\n",
    "    for j in [2,3,4,5,7,9,11,15,18,20,23,25]:\n",
    "        clf = RF(n_estimators = i,max_depth = j)\n",
    "        clf = clf.fit(X_228d,y_train)\n",
    "        pred1 = clf.predict(X_228d)\n",
    "        #print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, pred1)))\n",
    "        acc = accuracy_score(y_train, pred1)\n",
    "        #print(\"Precision is {0:.2f}\".format(precision_score(y_train, pred1)))\n",
    "        precision = precision_score(y_train, pred1)\n",
    "        #print(\"Recall is {0:.2f}\".format(recall_score(y_train, pred1)))\n",
    "        recall = recall_score(y_train, pred1)\n",
    "        #print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train,pred1)))\n",
    "        auc = roc_auc_score(y_train,pred1)\n",
    "        #print(\"f1 is {0:.2f}\".format(f1_score(y_train,pred1)))\n",
    "        f1 = f1_score(y_train,pred1)\n",
    "        print(classification_report(y_train,pred1))\n",
    "        file='/home/roopal/rf_model/'+str(i)+str(j)+'rf.pkl'\n",
    "        \n",
    "        pickle.dump(clf, open(file, 'wb'))\n",
    "        \n",
    "        f.write(str(acc)+\",\"+str(precision)+\",\"+str(recall)+\",\"+str(auc)+\",\"+str(f1))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "#f.write(\"\\n\".join(precision))\n",
    "#f.write(\"\\n\".join(recall))\n",
    "#f.write(\"\\n\".join(f1))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80096,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.00      0.00     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.81      0.50      0.39    106872\n",
      "weighted avg       0.76      0.65      0.51    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.04      0.07     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.76      0.52      0.43    106872\n",
      "weighted avg       0.73      0.66      0.54    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.00      0.00     37396\n",
      "           1       0.65      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    106872\n",
      "   macro avg       0.81      0.50      0.40    106872\n",
      "weighted avg       0.76      0.65      0.51    106872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.04      0.08     37396\n",
      "           1       0.66      1.00      0.79     69476\n",
      "\n",
      "   micro avg       0.66      0.66      0.66    106872\n",
      "   macro avg       0.75      0.52      0.44    106872\n",
      "weighted avg       0.72      0.66      0.54    106872\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     20025\n",
      "   macro avg       0.56      0.50      0.10     20025\n",
      "weighted avg       0.90      0.11      0.02     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     20025\n",
      "   macro avg       0.56      0.50      0.11     20025\n",
      "weighted avg       0.90      0.12      0.03     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.03      0.05     17784\n",
      "           1       0.11      0.99      0.20      2241\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     20025\n",
      "   macro avg       0.53      0.51      0.13     20025\n",
      "weighted avg       0.86      0.13      0.07     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.05      0.10     17784\n",
      "           1       0.11      0.98      0.21      2241\n",
      "\n",
      "   micro avg       0.15      0.15      0.15     20025\n",
      "   macro avg       0.53      0.51      0.15     20025\n",
      "weighted avg       0.85      0.15      0.11     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.10      0.18     17784\n",
      "           1       0.12      0.96      0.21      2241\n",
      "\n",
      "   micro avg       0.19      0.19      0.19     20025\n",
      "   macro avg       0.53      0.53      0.19     20025\n",
      "weighted avg       0.86      0.19      0.18     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.13      0.23     17784\n",
      "           1       0.12      0.93      0.21      2241\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     20025\n",
      "   macro avg       0.53      0.53      0.22     20025\n",
      "weighted avg       0.85      0.22      0.23     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.17      0.28     17784\n",
      "           1       0.12      0.91      0.21      2241\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     20025\n",
      "   macro avg       0.53      0.54      0.25     20025\n",
      "weighted avg       0.84      0.25      0.27     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38     17784\n",
      "           1       0.13      0.87      0.22      2241\n",
      "\n",
      "   micro avg       0.31      0.31      0.31     20025\n",
      "   macro avg       0.53      0.56      0.30     20025\n",
      "weighted avg       0.85      0.31      0.37     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.46     17784\n",
      "           1       0.13      0.82      0.22      2241\n",
      "\n",
      "   micro avg       0.36      0.36      0.36     20025\n",
      "   macro avg       0.53      0.56      0.34     20025\n",
      "weighted avg       0.84      0.36      0.43     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.34      0.49     17784\n",
      "           1       0.13      0.78      0.22      2241\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     20025\n",
      "   macro avg       0.53      0.56      0.36     20025\n",
      "weighted avg       0.83      0.39      0.46     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.37      0.53     17784\n",
      "           1       0.13      0.76      0.23      2241\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     20025\n",
      "   macro avg       0.53      0.57      0.38     20025\n",
      "weighted avg       0.84      0.41      0.49     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.39      0.55     17784\n",
      "           1       0.13      0.72      0.22      2241\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     20025\n",
      "   macro avg       0.52      0.56      0.38     20025\n",
      "weighted avg       0.83      0.43      0.51     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     20025\n",
      "   macro avg       0.56      0.50      0.10     20025\n",
      "weighted avg       0.90      0.11      0.02     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.01      0.01     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     20025\n",
      "   macro avg       0.54      0.50      0.11     20025\n",
      "weighted avg       0.88      0.12      0.03     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.02      0.05     17784\n",
      "           1       0.11      0.99      0.20      2241\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     20025\n",
      "   macro avg       0.54      0.51      0.13     20025\n",
      "weighted avg       0.87      0.13      0.06     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.06      0.10     17784\n",
      "           1       0.12      0.98      0.21      2241\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     20025\n",
      "   macro avg       0.53      0.52      0.16     20025\n",
      "weighted avg       0.86      0.16      0.12     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.09      0.16     17784\n",
      "           1       0.12      0.96      0.21      2241\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     20025\n",
      "   macro avg       0.53      0.52      0.18     20025\n",
      "weighted avg       0.85      0.18      0.16     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.12      0.22     17784\n",
      "           1       0.12      0.94      0.21      2241\n",
      "\n",
      "   micro avg       0.21      0.21      0.21     20025\n",
      "   macro avg       0.53      0.53      0.21     20025\n",
      "weighted avg       0.85      0.21      0.22     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.16      0.28     17784\n",
      "           1       0.12      0.91      0.21      2241\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     20025\n",
      "   macro avg       0.53      0.54      0.24     20025\n",
      "weighted avg       0.85      0.25      0.27     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38     17784\n",
      "           1       0.13      0.87      0.22      2241\n",
      "\n",
      "   micro avg       0.31      0.31      0.31     20025\n",
      "   macro avg       0.53      0.55      0.30     20025\n",
      "weighted avg       0.84      0.31      0.36     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.45     17784\n",
      "           1       0.13      0.83      0.22      2241\n",
      "\n",
      "   micro avg       0.36      0.36      0.36     20025\n",
      "   macro avg       0.53      0.56      0.34     20025\n",
      "weighted avg       0.84      0.36      0.43     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.33      0.49     17784\n",
      "           1       0.13      0.79      0.22      2241\n",
      "\n",
      "   micro avg       0.38      0.38      0.38     20025\n",
      "   macro avg       0.53      0.56      0.36     20025\n",
      "weighted avg       0.84      0.38      0.46     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.37      0.53     17784\n",
      "           1       0.13      0.76      0.23      2241\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     20025\n",
      "   macro avg       0.53      0.57      0.38     20025\n",
      "weighted avg       0.84      0.41      0.50     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.39      0.55     17784\n",
      "           1       0.13      0.74      0.23      2241\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     20025\n",
      "   macro avg       0.53      0.57      0.39     20025\n",
      "weighted avg       0.83      0.43      0.51     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     20025\n",
      "   macro avg       0.56      0.50      0.10     20025\n",
      "weighted avg       0.90      0.11      0.02     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.01      0.02     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     20025\n",
      "   macro avg       0.54      0.50      0.11     20025\n",
      "weighted avg       0.88      0.12      0.04     20025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.03      0.06     17784\n",
      "           1       0.11      0.99      0.20      2241\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     20025\n",
      "   macro avg       0.53      0.51      0.13     20025\n",
      "weighted avg       0.86      0.14      0.08     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.05      0.10     17784\n",
      "           1       0.12      0.98      0.21      2241\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     20025\n",
      "   macro avg       0.53      0.52      0.15     20025\n",
      "weighted avg       0.86      0.16      0.11     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.09      0.16     17784\n",
      "           1       0.12      0.96      0.21      2241\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     20025\n",
      "   macro avg       0.53      0.52      0.18     20025\n",
      "weighted avg       0.85      0.18      0.17     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.12      0.22     17784\n",
      "           1       0.12      0.94      0.21      2241\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     20025\n",
      "   macro avg       0.53      0.53      0.22     20025\n",
      "weighted avg       0.85      0.22      0.22     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.16      0.28     17784\n",
      "           1       0.12      0.92      0.21      2241\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     20025\n",
      "   macro avg       0.53      0.54      0.25     20025\n",
      "weighted avg       0.85      0.25      0.27     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38     17784\n",
      "           1       0.13      0.87      0.22      2241\n",
      "\n",
      "   micro avg       0.31      0.31      0.31     20025\n",
      "   macro avg       0.53      0.55      0.30     20025\n",
      "weighted avg       0.84      0.31      0.37     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.45     17784\n",
      "           1       0.13      0.83      0.22      2241\n",
      "\n",
      "   micro avg       0.36      0.36      0.36     20025\n",
      "   macro avg       0.53      0.56      0.34     20025\n",
      "weighted avg       0.84      0.36      0.43     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.33      0.49     17784\n",
      "           1       0.13      0.80      0.23      2241\n",
      "\n",
      "   micro avg       0.38      0.38      0.38     20025\n",
      "   macro avg       0.53      0.57      0.36     20025\n",
      "weighted avg       0.84      0.38      0.46     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.37      0.53     17784\n",
      "           1       0.13      0.76      0.22      2241\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     20025\n",
      "   macro avg       0.53      0.56      0.38     20025\n",
      "weighted avg       0.84      0.41      0.49     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.39      0.55     17784\n",
      "           1       0.13      0.75      0.23      2241\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     20025\n",
      "   macro avg       0.53      0.57      0.39     20025\n",
      "weighted avg       0.84      0.43      0.51     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     20025\n",
      "   macro avg       0.56      0.50      0.10     20025\n",
      "weighted avg       0.90      0.11      0.02     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.01      0.02     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     20025\n",
      "   macro avg       0.54      0.50      0.11     20025\n",
      "weighted avg       0.88      0.12      0.04     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.03      0.06     17784\n",
      "           1       0.11      0.99      0.20      2241\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     20025\n",
      "   macro avg       0.53      0.51      0.13     20025\n",
      "weighted avg       0.86      0.14      0.07     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.05      0.10     17784\n",
      "           1       0.12      0.98      0.21      2241\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     20025\n",
      "   macro avg       0.53      0.52      0.15     20025\n",
      "weighted avg       0.86      0.16      0.11     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.09      0.16     17784\n",
      "           1       0.12      0.96      0.21      2241\n",
      "\n",
      "   micro avg       0.19      0.19      0.19     20025\n",
      "   macro avg       0.53      0.53      0.19     20025\n",
      "weighted avg       0.86      0.19      0.17     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.12      0.22     17784\n",
      "           1       0.12      0.94      0.21      2241\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     20025\n",
      "   macro avg       0.53      0.53      0.22     20025\n",
      "weighted avg       0.85      0.22      0.22     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.16      0.27     17784\n",
      "           1       0.12      0.92      0.21      2241\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     20025\n",
      "   macro avg       0.53      0.54      0.24     20025\n",
      "weighted avg       0.85      0.25      0.27     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38     17784\n",
      "           1       0.13      0.87      0.22      2241\n",
      "\n",
      "   micro avg       0.31      0.31      0.31     20025\n",
      "   macro avg       0.53      0.56      0.30     20025\n",
      "weighted avg       0.85      0.31      0.36     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.45     17784\n",
      "           1       0.13      0.82      0.22      2241\n",
      "\n",
      "   micro avg       0.36      0.36      0.36     20025\n",
      "   macro avg       0.53      0.56      0.34     20025\n",
      "weighted avg       0.84      0.36      0.42     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.33      0.49     17784\n",
      "           1       0.13      0.80      0.22      2241\n",
      "\n",
      "   micro avg       0.38      0.38      0.38     20025\n",
      "   macro avg       0.53      0.56      0.36     20025\n",
      "weighted avg       0.84      0.38      0.46     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.37      0.53     17784\n",
      "           1       0.13      0.76      0.23      2241\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     20025\n",
      "   macro avg       0.53      0.57      0.38     20025\n",
      "weighted avg       0.84      0.41      0.50     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.39      0.54     17784\n",
      "           1       0.13      0.75      0.23      2241\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     20025\n",
      "   macro avg       0.53      0.57      0.39     20025\n",
      "weighted avg       0.84      0.43      0.51     20025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roopal/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     20025\n",
      "   macro avg       0.06      0.50      0.10     20025\n",
      "weighted avg       0.01      0.11      0.02     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.02     17784\n",
      "           1       0.11      1.00      0.20      2241\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     20025\n",
      "   macro avg       0.55      0.50      0.11     20025\n",
      "weighted avg       0.88      0.12      0.04     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.03      0.06     17784\n",
      "           1       0.11      0.99      0.20      2241\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     20025\n",
      "   macro avg       0.53      0.51      0.13     20025\n",
      "weighted avg       0.86      0.14      0.07     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.05      0.10     17784\n",
      "           1       0.12      0.98      0.21      2241\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     20025\n",
      "   macro avg       0.53      0.52      0.15     20025\n",
      "weighted avg       0.86      0.16      0.12     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.09      0.16     17784\n",
      "           1       0.12      0.96      0.21      2241\n",
      "\n",
      "   micro avg       0.19      0.19      0.19     20025\n",
      "   macro avg       0.53      0.52      0.18     20025\n",
      "weighted avg       0.86      0.19      0.17     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.12      0.22     17784\n",
      "           1       0.12      0.94      0.21      2241\n",
      "\n",
      "   micro avg       0.21      0.21      0.21     20025\n",
      "   macro avg       0.53      0.53      0.21     20025\n",
      "weighted avg       0.85      0.21      0.22     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.16      0.27     17784\n",
      "           1       0.12      0.92      0.21      2241\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     20025\n",
      "   macro avg       0.53      0.54      0.24     20025\n",
      "weighted avg       0.85      0.25      0.27     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38     17784\n",
      "           1       0.13      0.87      0.22      2241\n",
      "\n",
      "   micro avg       0.31      0.31      0.31     20025\n",
      "   macro avg       0.53      0.56      0.30     20025\n",
      "weighted avg       0.85      0.31      0.37     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.45     17784\n",
      "           1       0.13      0.82      0.22      2241\n",
      "\n",
      "   micro avg       0.36      0.36      0.36     20025\n",
      "   macro avg       0.53      0.56      0.34     20025\n",
      "weighted avg       0.84      0.36      0.42     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.33      0.49     17784\n",
      "           1       0.13      0.80      0.22      2241\n",
      "\n",
      "   micro avg       0.38      0.38      0.38     20025\n",
      "   macro avg       0.53      0.56      0.36     20025\n",
      "weighted avg       0.84      0.38      0.46     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.37      0.53     17784\n",
      "           1       0.13      0.77      0.23      2241\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     20025\n",
      "   macro avg       0.53      0.57      0.38     20025\n",
      "weighted avg       0.84      0.41      0.49     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.39      0.55     17784\n",
      "           1       0.13      0.75      0.23      2241\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     20025\n",
      "   macro avg       0.53      0.57      0.39     20025\n",
      "weighted avg       0.84      0.43      0.51     20025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "f= open(\"testre.txt\",\"a+\")\n",
    "import pickle\n",
    "f.write('accuracy'+\",\"+'Precision'+\",\"+'Recall'+\",\"+'AUC')\n",
    "f.write(\"\\n\")\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "auc = []\n",
    "f1 = []\n",
    "\n",
    "for i in [50,100,200,250,300]:\n",
    "    for j in [2,3,4,5,7,9,11,15,18,20,23,25]:\n",
    "        file='/home/roopal/rf_model/'+str(i)+str(j)+'rf.pkl'\n",
    "        load_clf = pickle.load(open(file, 'rb'))\n",
    "        \n",
    "        load_clf.fit(X_228d,y_train)\n",
    "        pred1 = load_clf.predict(y_228d)\n",
    "        #print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, pred1)))\n",
    "        acc = accuracy_score(Y_test, pred1)\n",
    "        #print(\"Precision is {0:.2f}\".format(precision_score(y_train, pred1)))\n",
    "        precision = precision_score(Y_test, pred1)\n",
    "        #print(\"Recall is {0:.2f}\".format(recall_score(y_train, pred1)))\n",
    "        recall = recall_score(Y_test, pred1)\n",
    "        #print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train,pred1)))\n",
    "        auc = roc_auc_score(Y_test,pred1)\n",
    "        #print(\"f1 is {0:.2f}\".format(f1_score(y_train,pred1)))\n",
    "        f1 = f1_score(Y_test,pred1)\n",
    "        print(classification_report(Y_test,pred1))\n",
    "        f.write(str(acc)+\",\"+str(precision)+\",\"+str(recall)+\",\"+str(auc)+\",\"+str(f1))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "#f.write(\"\\n\".join(precision))\n",
    "#f.write(\"\\n\".join(recall))\n",
    "#f.write(\"\\n\".join(f1))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.metrics import classification_report \\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\\nf= open(\"d.txt\",\"a+\")\\nacc = []\\nprecision = []\\nrecall = []\\nauc = []\\nf1 = []\\nf.write(\\'accuracy\\'+\",\"+\\'Precision\\'+\",\"+\\'Recall\\'+\",\"+\\'AUC\\')\\nfor i in [50]:\\n    for j in [2,3,4]:\\n        clf = RF(n_estimators = i,max_depth = j)\\n        clf = clf.fit(X_228d,y_train)\\n        pred1 = clf.predict(X_228d)\\n        #print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, pred1)))\\n        acc = accuracy_score(y_train, pred1)\\n        #print(\"Precision is {0:.2f}\".format(precision_score(y_train, pred1)))\\n        precision = precision_score(y_train, pred1)\\n        #print(\"Recall is {0:.2f}\".format(recall_score(y_train, pred1)))\\n        recall = recall_score(y_train, pred1)\\n        #print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train,pred1)))\\n        auc = roc_auc_score(y_train,pred1)\\n        #print(\"f1 is {0:.2f}\".format(f1_score(y_train,pred1)))\\n        f1 = f1_score(y_train,pred1)\\n        print(classification_report(y_train,pred1))\\n        f.write(str(acc)+\",\"+str(precision)+\",\"+str(recall)+\",\"+str(auc))\\n        f.write(\"\\n\")\\n        \\n#f.write(\"\\n\".join(precision))\\n#f.write(\"\\n\".join(recall))\\n#f.write(\"\\n\".join(f1))\\n    \\nf.close()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "f= open(\"d.txt\",\"a+\")\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "auc = []\n",
    "f1 = []\n",
    "f.write('accuracy'+\",\"+'Precision'+\",\"+'Recall'+\",\"+'AUC')\n",
    "for i in [50]:\n",
    "    for j in [2,3,4]:\n",
    "        clf = RF(n_estimators = i,max_depth = j)\n",
    "        clf = clf.fit(X_228d,y_train)\n",
    "        pred1 = clf.predict(X_228d)\n",
    "        #print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, pred1)))\n",
    "        acc = accuracy_score(y_train, pred1)\n",
    "        #print(\"Precision is {0:.2f}\".format(precision_score(y_train, pred1)))\n",
    "        precision = precision_score(y_train, pred1)\n",
    "        #print(\"Recall is {0:.2f}\".format(recall_score(y_train, pred1)))\n",
    "        recall = recall_score(y_train, pred1)\n",
    "        #print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train,pred1)))\n",
    "        auc = roc_auc_score(y_train,pred1)\n",
    "        #print(\"f1 is {0:.2f}\".format(f1_score(y_train,pred1)))\n",
    "        f1 = f1_score(y_train,pred1)\n",
    "        print(classification_report(y_train,pred1))\n",
    "        f.write(str(acc)+\",\"+str(precision)+\",\"+str(recall)+\",\"+str(auc))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "#f.write(\"\\n\".join(precision))\n",
    "#f.write(\"\\n\".join(recall))\n",
    "#f.write(\"\\n\".join(f1))\n",
    "    \n",
    "f.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 88764, 1: 11357})\n",
      "Now dataset shape Counter({0: 70980, 1: 70980})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61     70980\n",
      "           1       0.61      0.61      0.61     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.61      0.61      0.61    141960\n",
      "weighted avg       0.61      0.61      0.61    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61     70980\n",
      "           1       0.61      0.64      0.63     70980\n",
      "\n",
      "   micro avg       0.62      0.62      0.62    141960\n",
      "   macro avg       0.62      0.62      0.62    141960\n",
      "weighted avg       0.62      0.62      0.62    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62     70980\n",
      "           1       0.63      0.63      0.63     70980\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    141960\n",
      "   macro avg       0.63      0.63      0.63    141960\n",
      "weighted avg       0.63      0.63      0.63    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63     70980\n",
      "           1       0.64      0.66      0.65     70980\n",
      "\n",
      "   micro avg       0.64      0.64      0.64    141960\n",
      "   macro avg       0.64      0.64      0.64    141960\n",
      "weighted avg       0.64      0.64      0.64    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67     70980\n",
      "           1       0.67      0.71      0.69     70980\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    141960\n",
      "   macro avg       0.68      0.68      0.68    141960\n",
      "weighted avg       0.68      0.68      0.68    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71     70980\n",
      "           1       0.71      0.76      0.73     70980\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    141960\n",
      "   macro avg       0.72      0.72      0.72    141960\n",
      "weighted avg       0.72      0.72      0.72    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77     70980\n",
      "           1       0.76      0.81      0.78     70980\n",
      "\n",
      "   micro avg       0.77      0.77      0.77    141960\n",
      "   macro avg       0.78      0.77      0.77    141960\n",
      "weighted avg       0.78      0.77      0.77    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91     70980\n",
      "           1       0.88      0.95      0.91     70980\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    141960\n",
      "   macro avg       0.91      0.91      0.91    141960\n",
      "weighted avg       0.91      0.91      0.91    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     70980\n",
      "           1       0.95      0.99      0.97     70980\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    141960\n",
      "   macro avg       0.97      0.97      0.97    141960\n",
      "weighted avg       0.97      0.97      0.97    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     70980\n",
      "           1       0.98      1.00      0.99     70980\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    141960\n",
      "   macro avg       0.99      0.99      0.99    141960\n",
      "weighted avg       0.99      0.99      0.99    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.61     70980\n",
      "           1       0.61      0.60      0.60     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.61      0.61      0.61    141960\n",
      "weighted avg       0.61      0.61      0.61    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61     70980\n",
      "           1       0.61      0.64      0.63     70980\n",
      "\n",
      "   micro avg       0.62      0.62      0.62    141960\n",
      "   macro avg       0.62      0.62      0.62    141960\n",
      "weighted avg       0.62      0.62      0.62    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63     70980\n",
      "           1       0.63      0.66      0.64     70980\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    141960\n",
      "   macro avg       0.64      0.63      0.63    141960\n",
      "weighted avg       0.64      0.63      0.63    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63     70980\n",
      "           1       0.64      0.67      0.65     70980\n",
      "\n",
      "   micro avg       0.64      0.64      0.64    141960\n",
      "   macro avg       0.64      0.64      0.64    141960\n",
      "weighted avg       0.64      0.64      0.64    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67     70980\n",
      "           1       0.67      0.71      0.69     70980\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    141960\n",
      "   macro avg       0.68      0.68      0.68    141960\n",
      "weighted avg       0.68      0.68      0.68    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     70980\n",
      "           1       0.71      0.76      0.73     70980\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    141960\n",
      "   macro avg       0.72      0.72      0.72    141960\n",
      "weighted avg       0.72      0.72      0.72    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77     70980\n",
      "           1       0.76      0.81      0.79     70980\n",
      "\n",
      "   micro avg       0.78      0.78      0.78    141960\n",
      "   macro avg       0.78      0.78      0.78    141960\n",
      "weighted avg       0.78      0.78      0.78    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91     70980\n",
      "           1       0.88      0.95      0.91     70980\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    141960\n",
      "   macro avg       0.91      0.91      0.91    141960\n",
      "weighted avg       0.91      0.91      0.91    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     70980\n",
      "           1       0.95      0.99      0.97     70980\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    141960\n",
      "   macro avg       0.97      0.97      0.97    141960\n",
      "weighted avg       0.97      0.97      0.97    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     70980\n",
      "           1       0.98      1.00      0.99     70980\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    141960\n",
      "   macro avg       0.99      0.99      0.99    141960\n",
      "weighted avg       0.99      0.99      0.99    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60     70980\n",
      "           1       0.60      0.61      0.61     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.61      0.61      0.61    141960\n",
      "weighted avg       0.61      0.61      0.61    141960\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61     70980\n",
      "           1       0.61      0.62      0.62     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.62      0.61      0.61    141960\n",
      "weighted avg       0.62      0.61      0.61    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63     70980\n",
      "           1       0.63      0.65      0.64     70980\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    141960\n",
      "   macro avg       0.63      0.63      0.63    141960\n",
      "weighted avg       0.63      0.63      0.63    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63     70980\n",
      "           1       0.64      0.66      0.65     70980\n",
      "\n",
      "   micro avg       0.64      0.64      0.64    141960\n",
      "   macro avg       0.64      0.64      0.64    141960\n",
      "weighted avg       0.64      0.64      0.64    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66     70980\n",
      "           1       0.66      0.71      0.69     70980\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    141960\n",
      "   macro avg       0.68      0.68      0.68    141960\n",
      "weighted avg       0.68      0.68      0.68    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     70980\n",
      "           1       0.71      0.76      0.73     70980\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    141960\n",
      "   macro avg       0.72      0.72      0.72    141960\n",
      "weighted avg       0.72      0.72      0.72    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77     70980\n",
      "           1       0.76      0.81      0.79     70980\n",
      "\n",
      "   micro avg       0.78      0.78      0.78    141960\n",
      "   macro avg       0.78      0.78      0.78    141960\n",
      "weighted avg       0.78      0.78      0.78    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92     70980\n",
      "           1       0.89      0.95      0.92     70980\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    141960\n",
      "   macro avg       0.92      0.92      0.92    141960\n",
      "weighted avg       0.92      0.92      0.92    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     70980\n",
      "           1       0.95      0.99      0.97     70980\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    141960\n",
      "   macro avg       0.97      0.97      0.97    141960\n",
      "weighted avg       0.97      0.97      0.97    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     70980\n",
      "           1       0.98      1.00      0.99     70980\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    141960\n",
      "   macro avg       0.99      0.99      0.99    141960\n",
      "weighted avg       0.99      0.99      0.99    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60     70980\n",
      "           1       0.60      0.62      0.61     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.61      0.61      0.61    141960\n",
      "weighted avg       0.61      0.61      0.61    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62     70980\n",
      "           1       0.62      0.63      0.62     70980\n",
      "\n",
      "   micro avg       0.62      0.62      0.62    141960\n",
      "   macro avg       0.62      0.62      0.62    141960\n",
      "weighted avg       0.62      0.62      0.62    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62     70980\n",
      "           1       0.62      0.65      0.64     70980\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    141960\n",
      "   macro avg       0.63      0.63      0.63    141960\n",
      "weighted avg       0.63      0.63      0.63    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64     70980\n",
      "           1       0.64      0.67      0.65     70980\n",
      "\n",
      "   micro avg       0.64      0.64      0.64    141960\n",
      "   macro avg       0.64      0.64      0.64    141960\n",
      "weighted avg       0.64      0.64      0.64    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67     70980\n",
      "           1       0.67      0.71      0.69     70980\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    141960\n",
      "   macro avg       0.68      0.68      0.68    141960\n",
      "weighted avg       0.68      0.68      0.68    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     70980\n",
      "           1       0.71      0.76      0.73     70980\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    141960\n",
      "   macro avg       0.72      0.72      0.72    141960\n",
      "weighted avg       0.72      0.72      0.72    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77     70980\n",
      "           1       0.76      0.82      0.79     70980\n",
      "\n",
      "   micro avg       0.78      0.78      0.78    141960\n",
      "   macro avg       0.78      0.78      0.78    141960\n",
      "weighted avg       0.78      0.78      0.78    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91     70980\n",
      "           1       0.89      0.95      0.92     70980\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    141960\n",
      "   macro avg       0.92      0.92      0.92    141960\n",
      "weighted avg       0.92      0.92      0.92    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     70980\n",
      "           1       0.95      0.99      0.97     70980\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    141960\n",
      "   macro avg       0.97      0.97      0.97    141960\n",
      "weighted avg       0.97      0.97      0.97    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     70980\n",
      "           1       0.98      1.00      0.99     70980\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    141960\n",
      "   macro avg       0.99      0.99      0.99    141960\n",
      "weighted avg       0.99      0.99      0.99    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61     70980\n",
      "           1       0.61      0.61      0.61     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.61      0.61      0.61    141960\n",
      "weighted avg       0.61      0.61      0.61    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61     70980\n",
      "           1       0.61      0.63      0.62     70980\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    141960\n",
      "   macro avg       0.61      0.61      0.61    141960\n",
      "weighted avg       0.61      0.61      0.61    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62     70980\n",
      "           1       0.62      0.64      0.63     70980\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    141960\n",
      "   macro avg       0.63      0.63      0.63    141960\n",
      "weighted avg       0.63      0.63      0.63    141960\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63     70980\n",
      "           1       0.64      0.66      0.65     70980\n",
      "\n",
      "   micro avg       0.64      0.64      0.64    141960\n",
      "   macro avg       0.64      0.64      0.64    141960\n",
      "weighted avg       0.64      0.64      0.64    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67     70980\n",
      "           1       0.67      0.71      0.69     70980\n",
      "\n",
      "   micro avg       0.68      0.68      0.68    141960\n",
      "   macro avg       0.68      0.68      0.68    141960\n",
      "weighted avg       0.68      0.68      0.68    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     70980\n",
      "           1       0.71      0.76      0.73     70980\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    141960\n",
      "   macro avg       0.72      0.72      0.72    141960\n",
      "weighted avg       0.72      0.72      0.72    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77     70980\n",
      "           1       0.76      0.82      0.79     70980\n",
      "\n",
      "   micro avg       0.78      0.78      0.78    141960\n",
      "   macro avg       0.78      0.78      0.78    141960\n",
      "weighted avg       0.78      0.78      0.78    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92     70980\n",
      "           1       0.89      0.95      0.92     70980\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    141960\n",
      "   macro avg       0.92      0.92      0.92    141960\n",
      "weighted avg       0.92      0.92      0.92    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     70980\n",
      "           1       0.96      0.99      0.97     70980\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    141960\n",
      "   macro avg       0.98      0.97      0.97    141960\n",
      "weighted avg       0.98      0.97      0.97    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     70980\n",
      "           1       0.98      1.00      0.99     70980\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    141960\n",
      "   macro avg       0.99      0.99      0.99    141960\n",
      "weighted avg       0.99      0.99      0.99    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70980\n",
      "           1       1.00      1.00      1.00     70980\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    141960\n",
      "   macro avg       1.00      1.00      1.00    141960\n",
      "weighted avg       1.00      1.00      1.00    141960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.65     17784\n",
      "           1       0.14      0.62      0.22      2241\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20025\n",
      "   macro avg       0.52      0.56      0.43     20025\n",
      "weighted avg       0.83      0.52      0.60     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.49      0.64     17784\n",
      "           1       0.13      0.62      0.22      2241\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     20025\n",
      "   macro avg       0.52      0.56      0.43     20025\n",
      "weighted avg       0.82      0.51      0.59     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.65     17784\n",
      "           1       0.14      0.63      0.23      2241\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20025\n",
      "   macro avg       0.53      0.56      0.44     20025\n",
      "weighted avg       0.83      0.52      0.60     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.50      0.65     17784\n",
      "           1       0.14      0.64      0.23      2241\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20025\n",
      "   macro avg       0.53      0.57      0.44     20025\n",
      "weighted avg       0.83      0.52      0.60     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.50      0.65     17784\n",
      "           1       0.14      0.64      0.23      2241\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20025\n",
      "   macro avg       0.53      0.57      0.44     20025\n",
      "weighted avg       0.83      0.52      0.60     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.52      0.66     17784\n",
      "           1       0.14      0.63      0.23      2241\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     20025\n",
      "   macro avg       0.53      0.57      0.45     20025\n",
      "weighted avg       0.83      0.53      0.61     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.54      0.68     17784\n",
      "           1       0.14      0.61      0.23      2241\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     20025\n",
      "   macro avg       0.53      0.58      0.46     20025\n",
      "weighted avg       0.83      0.55      0.63     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.62      0.74     17784\n",
      "           1       0.14      0.52      0.23      2241\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     20025\n",
      "   macro avg       0.53      0.57      0.48     20025\n",
      "weighted avg       0.82      0.61      0.68     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77     17784\n",
      "           1       0.15      0.47      0.23      2241\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     20025\n",
      "   macro avg       0.53      0.57      0.50     20025\n",
      "weighted avg       0.82      0.64      0.71     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.79     17784\n",
      "           1       0.15      0.44      0.23      2241\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     20025\n",
      "   macro avg       0.53      0.56      0.51     20025\n",
      "weighted avg       0.82      0.67      0.72     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.81     17784\n",
      "           1       0.15      0.39      0.22      2241\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     20025\n",
      "   macro avg       0.53      0.56      0.51     20025\n",
      "weighted avg       0.82      0.69      0.74     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82     17784\n",
      "           1       0.15      0.37      0.22      2241\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     20025\n",
      "   macro avg       0.53      0.56      0.52     20025\n",
      "weighted avg       0.82      0.70      0.75     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.64     17784\n",
      "           1       0.13      0.62      0.22      2241\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     20025\n",
      "   macro avg       0.52      0.56      0.43     20025\n",
      "weighted avg       0.83      0.51      0.60     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.51      0.65     17784\n",
      "           1       0.14      0.63      0.23      2241\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20025\n",
      "   macro avg       0.53      0.57      0.44     20025\n",
      "weighted avg       0.83      0.52      0.60     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.49      0.64     17784\n",
      "           1       0.14      0.64      0.23      2241\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     20025\n",
      "   macro avg       0.53      0.57      0.43     20025\n",
      "weighted avg       0.83      0.51      0.59     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.51      0.66     17784\n",
      "           1       0.14      0.63      0.23      2241\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     20025\n",
      "   macro avg       0.53      0.57      0.44     20025\n",
      "weighted avg       0.83      0.53      0.61     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.49      0.64     17784\n",
      "           1       0.14      0.65      0.23      2241\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     20025\n",
      "   macro avg       0.53      0.57      0.44     20025\n",
      "weighted avg       0.83      0.51      0.60     20025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.51      0.66     17784\n",
      "           1       0.14      0.64      0.23      2241\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     20025\n",
      "   macro avg       0.53      0.58      0.45     20025\n",
      "weighted avg       0.83      0.53      0.61     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.54      0.68     17784\n",
      "           1       0.14      0.61      0.23      2241\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     20025\n",
      "   macro avg       0.53      0.57      0.45     20025\n",
      "weighted avg       0.83      0.55      0.63     20025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73     17784\n",
      "           1       0.15      0.53      0.23      2241\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20025\n",
      "   macro avg       0.53      0.57      0.48     20025\n",
      "weighted avg       0.83      0.60      0.68     20025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "df = pd.read_csv(\"/home/roopal/diabetes_data_preprocessed_big.csv\")\n",
    "df['readmitted'] = df['readmitted'].apply(lambda x: 0 if x == 2 else x)\n",
    "df1 = df[['race','gender','age','admission_type_id','discharge_disposition_id','admission_source_id','time_in_hospital','num_lab_procedures','num_procedures','num_medications','number_outpatient','number_emergency','number_inpatient','diag_1','diag_2','diag_3','number_diagnoses','max_glu_serum','A1Cresult','insulin','change','diabetesMed']]\n",
    "df1 = pd.get_dummies(df1, columns=['race'], drop_first = True)\n",
    "y = df['readmitted']\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "import numpy as np\n",
    "df['number_outpatient'] = np.log1p(df['number_outpatient'])\n",
    "df['number_inpatient'] = np.log1p(df['number_inpatient'])\n",
    "df['number_emergency'] = np.log1p(df['number_emergency'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE(random_state=20,sampling_strategy='all',ratio=None)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df1,y, test_size=0.20, random_state=0)\n",
    "x_train, y_train = smt.fit_sample(X_train, Y_train)\n",
    "print('Now dataset shape {}'.format(Counter(y_train)))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#X = x_train.values\n",
    "X_std = StandardScaler().fit_transform(x_train)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "# Create a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the eigenvalue, eigenvector pair from high to low\n",
    "eig_pairs.sort(key = lambda x: x[0], reverse= True)\n",
    "\n",
    "# Calculation of Explained Variance from the eigenvalues\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) \n",
    "[ n for n,i in enumerate(cum_var_exp) if i>90 ][0]\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=19)\n",
    "pca.fit(X_std)\n",
    "X_228d = pca.transform(X_std)\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "y = X_test.values\n",
    "y_std = StandardScaler().fit_transform(y)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "y_228d = pca.transform(y_std)\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "import pickle\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "auc = []\n",
    "f1 = []\n",
    "f= open(\"tr.txt\",\"a+\")\n",
    "f.write('accuracy'+\",\"+'Precision'+\",\"+'Recall'+\",\"+'AUC')\n",
    "f.write(\"\\n\")\n",
    "for i in [50,100,200,250,300]:\n",
    "    for j in [2,3,4,5,7,9,11,15,18,20,23,25]:\n",
    "        clf = RF(n_estimators = i,max_depth = j)\n",
    "        clf = clf.fit(X_228d,y_train)\n",
    "        pred1 = clf.predict(X_228d)\n",
    "        #print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, pred1)))\n",
    "        acc = accuracy_score(y_train, pred1)\n",
    "        #print(\"Precision is {0:.2f}\".format(precision_score(y_train, pred1)))\n",
    "        precision = precision_score(y_train, pred1)\n",
    "        #print(\"Recall is {0:.2f}\".format(recall_score(y_train, pred1)))\n",
    "        recall = recall_score(y_train, pred1)\n",
    "        #print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train,pred1)))\n",
    "        auc = roc_auc_score(y_train,pred1)\n",
    "        #print(\"f1 is {0:.2f}\".format(f1_score(y_train,pred1)))\n",
    "        f1 = f1_score(y_train,pred1)\n",
    "        print(classification_report(y_train,pred1))\n",
    "        file='/home/roopal/rf_model/'+str(i)+str(j)+'rf.pkl'\n",
    "        \n",
    "        pickle.dump(clf, open(file, 'wb'))\n",
    "        \n",
    "        f.write(str(acc)+\",\"+str(precision)+\",\"+str(recall)+\",\"+str(auc)+\",\"+str(f1))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "#f.write(\"\\n\".join(precision))\n",
    "#f.write(\"\\n\".join(recall))\n",
    "#f.write(\"\\n\".join(f1))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "f= open(\"testre.txt\",\"a+\")\n",
    "import pickle\n",
    "f.write('accuracy'+\",\"+'Precision'+\",\"+'Recall'+\",\"+'AUC')\n",
    "f.write(\"\\n\")\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "auc = []\n",
    "f1 = []\n",
    "\n",
    "for i in [50,100,200,250,300]:\n",
    "    for j in [2,3,4,5,7,9,11,15,18,20,23,25]:\n",
    "        file='/home/roopal/rf_model/'+str(i)+str(j)+'rf.pkl'\n",
    "        load_clf = pickle.load(open(file, 'rb'))\n",
    "        \n",
    "        load_clf.fit(X_228d,y_train)\n",
    "        pred1 = load_clf.predict(y_228d)\n",
    "        #print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, pred1)))\n",
    "        acc = accuracy_score(Y_test, pred1)\n",
    "        #print(\"Precision is {0:.2f}\".format(precision_score(y_train, pred1)))\n",
    "        precision = precision_score(Y_test, pred1)\n",
    "        #print(\"Recall is {0:.2f}\".format(recall_score(y_train, pred1)))\n",
    "        recall = recall_score(Y_test, pred1)\n",
    "        #print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train,pred1)))\n",
    "        auc = roc_auc_score(Y_test,pred1)\n",
    "        #print(\"f1 is {0:.2f}\".format(f1_score(y_train,pred1)))\n",
    "        f1 = f1_score(Y_test,pred1)\n",
    "        print(classification_report(Y_test,pred1))\n",
    "        f.write(str(acc)+\",\"+str(precision)+\",\"+str(recall)+\",\"+str(auc)+\",\"+str(f1))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "#f.write(\"\\n\".join(precision))\n",
    "#f.write(\"\\n\".join(recall))\n",
    "#f.write(\"\\n\".join(f1))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
